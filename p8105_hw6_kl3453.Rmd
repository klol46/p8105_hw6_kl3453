---
title: "HW6: Markdown file"
author: "Kevin Liu"
date: "2023-12-02"
output: github_document
---

```{r include = FALSE}
library(rvest)
library(tidyverse)
library(modelr)
library(mgcv)

```

# Problem 1

The Washington Post has gathered data on homicides in 50 large U.S. cities and made the data available through a GitHub repository here. You can read their accompanying article here.

```{r, echo = FALSE}
raw_homicide_data =
  read_csv("./data/homicide-data.csv") |> 
  janitor::clean_names()
```

__Data Process__

Create a city_state variable (e.g. “Baltimore, MD”), and a binary variable indicating whether the homicide is solved.

  - Omit: Dallas, TX, Phoeniz, AZ, Kansas City, MO, and Tulsa Al
  - Include only when victim_race == "white" or "black"
  - victim_age has to be numeric 

```{r}
processs_homicide_data = 
  raw_homicide_data |> 
  
  #Create variable "city_state" which is a concatenation of city + state separated by , .
  mutate(city_state = paste(city, state, sep = ", ")) |> 
  
  #Omit Dallas, Phoenix, Kansas Ciry, and Tulsa
  filter(!grepl("Dallas, TX|Phoenix, AZ|Kansas City, MO|Tulsa, AL", city_state)) |> 
  
  #Include victim_race == "white" or "black"
  filter(grepl("White|Black", victim_race)) |> 
  
  #victim_age is numeric
  mutate(victim_age = as.numeric(victim_age))
```

## For the city of Baltimore, MD, use the glm function...

to fit a _logistic regression_ with resolved vs unresolved as the outcome and victim age, sex and race as predictors. 

  - Outcome: Resolved vs. Unresolved (1 or 0 Binary)
  - Predictors
      - Age (Continuous)
      - Sex (Binary)
      - Race (Binary)

__Resolved vs. Unresolved (Binary Var)__
```{r}
#Process Data
resolved_data =
  processs_homicide_data |> 
  
  #create binary variable that is 1 or 0 dpeending on if resolved or not
  mutate(resolve = ifelse(disposition %in% c("Closed without arrest", "Open/No arrest"), 0, 1)) 
  
  #NOTE: glm is able to automatically define binary despite the variables being defined as strings. Race + Sex left alone
```

__Logistic Regression__
```{r}
homicide_logistic =
  resolved_data |> 
  glm(resolve ~ victim_age + victim_race + victim_sex, data = _, family = binomial()) 
```

__Tidy__

Save the output of glm as an R object; apply the broom::tidy to this object; 

```{r, results = "hide"}
#Extract all parameter estimates from logistic regression
homicide_param_est = 
  homicide_logistic |> 
  broom::tidy() |> 
  
  #Calculating OR from the log(OR) and OR_CI
  mutate(OR = exp(estimate), OR_CI = exp(confint.default(homicide_logistic))) |>
  select(term, log_OR = estimate, OR, OR_CI, p.value)
```


__OR of Male vs. Female__

Obtain the estimate and confidence interval of the adjusted odds ratio for solving homicides comparing male victims to female victims keeping all other variables fixed.

```{r}
homicide_param_est_male_female = 
  homicide_param_est |> 
  
  #Filter on parameter  estimate of the binary variable Male (1 = Male, 0 = Female)
  filter(grepl("victim_sexMale", term))
```

- OR Estimate = `r homicide_param_est_male_female$OR`
  - 95% CI: (`r homicide_param_est_male_female$OR_CI`)
  
## Now run glm for each of the cities in your dataset, 

and extract the adjusted odds ratio (and CI) for solving homicides comparing male victims to female victims. Do this within a “tidy” pipeline, making use of purrr::map, list columns, and unnest as necessary to create a dataframe with estimated ORs and CIs for each city.

__Broom function__
```{r}
#This is inorder to allow "tidy" to ouput confidence intervals into it's output, of which is default set to FALSE
broom_conf = function(df) {
  broom::tidy(df, conf.int = TRUE)
}
```

```{r, results = "hide"}
citystate_OR_CI_hom = 
  resolved_data |> 
  
  #Nest on city_state to perform log regression on each city state
  nest(data = -city_state) |> 
  mutate(
    models = map(data, \(df) glm(resolve ~ victim_age + victim_race + victim_sex, data = df, family = binomial())),
    results = map(models, broom_conf)) |> 
  select(-data, -models) |> 
  unnest(results) |> 
  
  #calculate OR and confidence interval for OR
  mutate(OR = exp(estimate), lowCI = exp(conf.low), uppCI = exp(conf.high)) |>
  filter(grepl("victim_sexMale", term)) |> 
  select(city_state, OR, lowCI, uppCI)
  
```

Create a plot that shows the estimated ORs and CIs for each city. Organize cities according to estimated OR, and comment on the plot.

```{r}
#Order the city_states by Magnitude of Odds Ratio
citystate_OR_CI_hom[order(citystate_OR_CI_hom$OR),] |>  
  
  #Order the city_states by their position using factors (for plotting purposes)
  mutate(city_state = factor(city_state, levels = city_state)) |>
  
  #Plot city_state vs. OR
  ggplot(aes(x = city_state, y = OR)) +
  
  #Error bars are the confidence intervals
  geom_errorbar(aes(ymin = lowCI, ymax = uppCI))+
  
  #flip coordinates to allow easy viewing
  coord_flip()
```

From the plot, we can see that half of the cities have an OR confidence interval that includes 1 (Null) which means that for those city_states, we are 95% confident that the odds of resolving as a male is same as the odds of resolving as a female.

The other half of city_states have OR confidence intervales that are below 1 and do not include 1 which means for these city_states, there is 95% confidence that the odds of resolving is lower as a male than female. 

# Problem 2

```{r, echo = FALSE}
# Central Park Weather Data
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())

```

The boostrap is helpful when you’d like to perform inference for a parameter / value / summary that doesn’t have an easy-to-write-down distribution in the usual repeated sampling framework. 

We’ll focus on a simple linear regression with _tmax_ as the response with _tmin_ and _prcp_ as the predictors, and are interested in the distribution of two quantities estimated from these data: r^2 + log(b1 * b2)

## Bootstrap

Use 5000 bootstrap samples and, for each bootstrap sample, produce estimates of these two quantities. Plot the distribution of your estimates, and describe these in words. Using the 5000 bootstrap estimates, identify the 2.5% and 97.5% quantiles to provide a 95% confidence interval for r̂ 2 and log(β̂ 0∗β̂ 1).

__5000 Boostrap Samples__
```{r}
weather_boostrap = 
  weather_df |> 
  select(-name, -id) |> 
  
  #bootstrap 5000 samples using dataset
  modelr::bootstrap(n = 5000) |> 
  mutate(
    models = map(strap, \(df) lm(tmax ~ tmin + prcp, data = df) ),
    
    #tidy results in order to get log(b1 * b2)
    results_tidy = map(models, broom::tidy),
    
    #glance results in order to get r^2 values 
    results_glance = map(models, broom::glance)) |> 
  select(-models) |> 
  unnest(results_tidy)
```

__r^2 Estimate + Conf. Interval__
```{r, results = "hide"}
#r^2 estimate plot + CI
r_squared =
  weather_boostrap |> 
  
  #Only include, id, term, and results glance
  select(.id, term, results_glance) |> 
  
  #unnest glance results in order to extract r^2 values
  unnest(results_glance) |> 
  group_by(.id) |>
  select(r.squared) |> 
  
  #since there are multiple terms, the r^2 is duplicated, selected distinct values
  distinct()

#Parameters to estimate confidence intervals
zval = qnorm(.975)

  #Take mean of all r^2 values
r_mean = mean(r_squared$r.squared)
  #estimate sd of all r^2 values
r_sd = sd(r_squared$r.squared)
  #record sample size
count = nrow(r_squared)
  #calculate marginal error (used to calculate 95% CI)
me = zval * (r_sd/sqrt(count))
```

  - r^2 Mean: `r r_mean`
  - r^2 95% CI: (`r r_mean - me`, `r r_mean + me`)

__r^2 plot__
```{r}
r_squared |> 
  ggplot(aes(x = r.squared)) +
  geom_density()
```

__log(beta1 * beta2)__
```{r}
log_b1_b2_df = 
  weather_boostrap |> 
  
  #select data from tidy
  select(.id, term, estimate) |> 
  
  #pivot wider in order to define beta1 * beta2 (creating separate column)
  pivot_wider(
    names_from = term,
    values_from = estimate
  ) |> 
  
  #calculate log(b1 * b2) 
  mutate(log_est = log(abs(tmin * prcp)))

#Parameters to estimate confidence intervals
zval = qnorm(.975)

  #Take mean of all r^2 values
log_mean = mean(log_b1_b2_df$log_est)
  #estimate sd of all r^2 values
log_sd = sd(log_b1_b2_df$log_est)
  #record sample size
count = nrow(log_b1_b2_df)
  #calculate marginal error (used to calculate 95% CI)
me_log = zval * (log_sd/sqrt(count))
```


  - log(b1*b2) Mean: `r log_mean`
  - log(b1*b2) 95% CI: (`r log_mean - me_log`, `r log_mean + me_log`)

__Plot log(b1 * b2)__
```{r}
log_b1_b2_df |> 
  ggplot(aes(x = log_est)) +
  geom_density()
  
```

NOTE: Maybe due to personal misunderstanding but the product of beta1 and beta2 results in negative values for certain values and thus produces a non-real value when performing the log of the product. Thus the density plot is skewed.

# Problem 3

In this problem, you will analyze data gathered to understand the effects of several variables on a child’s birthweight. This dataset, available here, consists of roughly 4000 children and includes the following variables:

Load and clean the data for regression analysis (i.e. convert numeric to factor where appropriate, check for missing data, etc.).

__Load__
```{r, results = "hide"}
raw_birthweight_data =
  read_csv("./data/birthweight.csv") |> 
  janitor::clean_names()
```

__Clean__
```{r}
birthweight_df = 
  raw_birthweight_data |> 
  
  #convert frace to categorical var, convert to factor
  mutate(frace = factor(frace)) |> 
  
  #convert mrace to categorical var, convert to factor
  mutate(mrace = factor(mrace))
```



## Propose + Compare your Models

__Proposed Model__ 

The proposed model will be a linear regression as the outcome is a continuous variable. 
  
  - BirthWeight = length, gestational age, sex, mrace, frace 
    
    - Hypothesis: race of mother/father may act as social factors that may significantly affect birthweight.

```{r}
proposed_model = lm(bwt ~ blength + gaweeks + babysex + mrace + frace, data = birthweight_df)
```


__Main Effect Model__

  - BirthWeight = Length at Birth + Gestational Age
```{r}
main_model = lm(bwt ~ blength + gaweeks, data = birthweight_df) 
```

__Three Way Model__

  - BirthWeight = Head Circumference, Length, Baby Sex, and All Interactions
  
```{r}
interaction_model = lm(bwt ~ blength + bhead + babysex + blength:bhead + blength:babysex + bhead:babysex + bhead:blength:babysex, data = birthweight_df)
```

### Comparing Models: Residuals vs. Predicted

__Create Test/Training Data__
```{r}
cv_bwt_df = 
  crossv_mc(birthweight_df, 100) |> 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)) |> 
  mutate(
      prop_mod = map(train, \(df) lm(bwt ~ blength + gaweeks + babysex + mrace + frace, data = df)),
      main_mod = map(train, \(df) lm(bwt ~ blength + gaweeks, data = df)),
      inter_mod = map(train, \(df) lm(bwt ~ blength + bhead + babysex + blength:bhead + blength:babysex + bhead:babysex + bhead:blength:babysex, data = df))
      ) |> 
  mutate(
    rmse_prop = map2_dbl(prop_mod, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_main    = map2_dbl(main_mod, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_inter = map2_dbl(inter_mod, test, \(mod, df) rmse(model = mod, data = df)))
  
```

__Proposed Model: Residuals vs. Predictors__

```{r}
#Take one test sample + plot the predictoed vs. residuals for each sample.
cv_bwt_df |> 
  pull(test) |> 
  nth(1) |> 
  as_tibble() |> 
  add_predictions(proposed_model) |> 
  add_residuals(proposed_model) |> 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() 
```

__Main Model: Residuals vs. Predictors__

```{r}
cv_bwt_df |> 
  pull(test) |> 
  nth(1) |> 
  as_tibble() |> 
  add_predictions(main_model) |> 
  add_residuals(main_model) |> 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() 
```

__3 Way Model: Residuals vs. Predictors__

```{r}
cv_bwt_df |> 
  pull(test) |> 
  nth(1) |> 
  as_tibble() |> 
  add_predictions(interaction_model) |> 
  add_residuals(interaction_model) |> 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() 
```

By comparing the models based on residuals and predictors, it seems they all fit quite similarly.

- In more detail, it seems that the 3 way model fits this particular test sample a bit better as the scatterplot is more tightly comppacted around the resid = 0 line.

### Comparing Models: MSE
```{r}
cv_bwt_df |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") |> 
  mutate(model = fct_inorder(model)) |> 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

As we can see, it seems the 3 way model performs slightly better than the main and the proposed model in terms of model fit to the data.