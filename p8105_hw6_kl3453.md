HW6: Markdown file
================
Kevin Liu
2023-12-02

# Problem 1

The Washington Post has gathered data on homicides in 50 large U.S.
cities and made the data available through a GitHub repository here. You
can read their accompanying article here.

    ## Rows: 52179 Columns: 12
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (9): uid, victim_last, victim_first, victim_race, victim_age, victim_sex...
    ## dbl (3): reported_date, lat, lon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

**Data Process**

Create a city_state variable (e.g. “Baltimore, MD”), and a binary
variable indicating whether the homicide is solved.

- Omit: Dallas, TX, Phoeniz, AZ, Kansas City, MO, and Tulsa Al
- Include only when victim_race == “white” or “black”
- victim_age has to be numeric

``` r
processs_homicide_data = 
  raw_homicide_data |> 
  
  #Create variable "city_state" which is a concatenation of city + state separated by , .
  mutate(city_state = paste(city, state, sep = ", ")) |> 
  
  #Omit Dallas, Phoenix, Kansas Ciry, and Tulsa
  filter(!grepl("Dallas, TX|Phoenix, AZ|Kansas City, MO|Tulsa, AL", city_state)) |> 
  
  #Include victim_race == "white" or "black"
  filter(grepl("White|Black", victim_race)) |> 
  
  #victim_age is numeric
  mutate(victim_age = as.numeric(victim_age))
```

    ## Warning: There was 1 warning in `mutate()`.
    ## ℹ In argument: `victim_age = as.numeric(victim_age)`.
    ## Caused by warning:
    ## ! NAs introduced by coercion

## For the city of Baltimore, MD, use the glm function…

to fit a *logistic regression* with resolved vs unresolved as the
outcome and victim age, sex and race as predictors.

- Outcome: Resolved vs. Unresolved (1 or 0 Binary)
- Predictors
  - Age (Continuous)
  - Sex (Binary)
  - Race (Binary)

**Resolved vs. Unresolved (Binary Var)**

``` r
#Process Data
resolved_data =
  processs_homicide_data |> 
  
  #create binary variable that is 1 or 0 dpeending on if resolved or not
  mutate(resolve = ifelse(disposition %in% c("Closed without arrest", "Open/No arrest"), 0, 1)) 
  
  #NOTE: glm is able to automatically define binary despite the variables being defined as strings. Race + Sex left alone
```

**Logistic Regression**

``` r
homicide_logistic =
  resolved_data |> 
  glm(resolve ~ victim_age + victim_race + victim_sex, data = _, family = binomial()) 
```

**Tidy**

Save the output of glm as an R object; apply the broom::tidy to this
object;

``` r
#Extract all parameter estimates from logistic regression
homicide_param_est = 
  homicide_logistic |> 
  broom::tidy() |> 
  
  #Calculating OR from the log(OR) and OR_CI
  mutate(OR = exp(estimate), OR_CI = exp(confint.default(homicide_logistic))) |>
  select(term, log_OR = estimate, OR, OR_CI, p.value)
```

**OR of Male vs. Female**

Obtain the estimate and confidence interval of the adjusted odds ratio
for solving homicides comparing male victims to female victims keeping
all other variables fixed.

``` r
homicide_param_est_male_female = 
  homicide_param_est |> 
  
  #Filter on parameter  estimate of the binary variable Male (1 = Male, 0 = Female)
  filter(grepl("victim_sexMale", term))
```

- OR Estimate = 0.6028675
  - 95% CI: (0.5688936, 0.6388704)

## Now run glm for each of the cities in your dataset,

and extract the adjusted odds ratio (and CI) for solving homicides
comparing male victims to female victims. Do this within a “tidy”
pipeline, making use of purrr::map, list columns, and unnest as
necessary to create a dataframe with estimated ORs and CIs for each
city.

**Broom function**

``` r
#This is inorder to allow "tidy" to ouput confidence intervals into it's output, of which is default set to FALSE
broom_conf = function(df) {
  broom::tidy(df, conf.int = TRUE)
}
```

``` r
citystate_OR_CI_hom = 
  resolved_data |> 
  
  #Nest on city_state to perform log regression on each city state
  nest(data = -city_state) |> 
  mutate(
    models = map(data, \(df) glm(resolve ~ victim_age + victim_race + victim_sex, data = df, family = binomial())),
    results = map(models, broom_conf)) |> 
  select(-data, -models) |> 
  unnest(results) |> 
  
  #calculate OR and confidence interval for OR
  mutate(OR = exp(estimate), lowCI = exp(conf.low), uppCI = exp(conf.high)) |>
  filter(grepl("victim_sexMale", term)) |> 
  select(city_state, OR, lowCI, uppCI)
```

    ## Warning: There were 44 warnings in `mutate()`.
    ## The first warning was:
    ## ℹ In argument: `results = map(models, broom_conf)`.
    ## Caused by warning:
    ## ! glm.fit: fitted probabilities numerically 0 or 1 occurred
    ## ℹ Run `dplyr::last_dplyr_warnings()` to see the 43 remaining warnings.

Create a plot that shows the estimated ORs and CIs for each city.
Organize cities according to estimated OR, and comment on the plot.

``` r
#Order the city_states by Magnitude of Odds Ratio
citystate_OR_CI_hom[order(citystate_OR_CI_hom$OR),] |>  
  
  #Order the city_states by their position using factors (for plotting purposes)
  mutate(city_state = factor(city_state, levels = city_state)) |>
  
  #Plot city_state vs. OR
  ggplot(aes(x = city_state, y = OR)) +
  
  #Error bars are the confidence intervals
  geom_errorbar(aes(ymin = lowCI, ymax = uppCI))+
  
  #flip coordinates to allow easy viewing
  coord_flip()
```

![](p8105_hw6_kl3453_files/figure-gfm/unnamed-chunk-10-1.png)<!-- -->

From the plot, we can see that half of the cities have an OR confidence
interval that includes 1 (Null) which means that for those city_states,
we are 95% confident that the odds of resolving as a male is same as the
odds of resolving as a female.

The other half of city_states have OR confidence intervales that are
below 1 and do not include 1 which means for these city_states, there is
95% confidence that the odds of resolving is lower as a male than
female.

# Problem 2

    ## Registered S3 method overwritten by 'hoardr':
    ##   method           from
    ##   print.cache_info httr

    ## using cached file: /Users/kl/Library/Caches/org.R-project.R/R/rnoaa/noaa_ghcnd/USW00094728.dly

    ## date created (size, mb): 2023-09-28 13:49:36.87383 (8.524)

    ## file min/max dates: 1869-01-01 / 2023-09-30

The boostrap is helpful when you’d like to perform inference for a
parameter / value / summary that doesn’t have an easy-to-write-down
distribution in the usual repeated sampling framework.

We’ll focus on a simple linear regression with *tmax* as the response
with *tmin* and *prcp* as the predictors, and are interested in the
distribution of two quantities estimated from these data: r^2 + log(b1
\* b2)

## Bootstrap

Use 5000 bootstrap samples and, for each bootstrap sample, produce
estimates of these two quantities. Plot the distribution of your
estimates, and describe these in words. Using the 5000 bootstrap
estimates, identify the 2.5% and 97.5% quantiles to provide a 95%
confidence interval for r̂ 2 and log(β̂ 0∗β̂ 1).

**5000 Boostrap Samples**

``` r
weather_boostrap = 
  weather_df |> 
  select(-name, -id) |> 
  
  #bootstrap 5000 samples using dataset
  modelr::bootstrap(n = 5000) |> 
  mutate(
    models = map(strap, \(df) lm(tmax ~ tmin + prcp, data = df) ),
    
    #tidy results in order to get log(b1 * b2)
    results_tidy = map(models, broom::tidy),
    
    #glance results in order to get r^2 values 
    results_glance = map(models, broom::glance)) |> 
  select(-models) |> 
  unnest(results_tidy)
```

**r^2 Estimate + Conf. Interval**

``` r
#r^2 estimate plot + CI
r_squared =
  weather_boostrap |> 
  
  #Only include, id, term, and results glance
  select(.id, term, results_glance) |> 
  
  #unnest glance results in order to extract r^2 values
  unnest(results_glance) |> 
  group_by(.id) |>
  select(r.squared) |> 
  
  #since there are multiple terms, the r^2 is duplicated, selected distinct values
  distinct()
```

    ## Adding missing grouping variables: `.id`

``` r
#Parameters to estimate confidence intervals
zval = qnorm(.975)

  #Take mean of all r^2 values
r_mean = mean(r_squared$r.squared)
  #estimate sd of all r^2 values
r_sd = sd(r_squared$r.squared)
  #record sample size
count = nrow(r_squared)
  #calculate marginal error (used to calculate 95% CI)
me = zval * (r_sd/sqrt(count))
```

- r^2 Mean: 0.9171175
- r^2 95% CI: (0.9167477, 0.9174873)

**r^2 plot**

``` r
r_squared |> 
  ggplot(aes(x = r.squared)) +
  geom_density()
```

![](p8105_hw6_kl3453_files/figure-gfm/unnamed-chunk-14-1.png)<!-- -->

**log(beta1 \* beta2)**

``` r
log_b1_b2_df = 
  weather_boostrap |> 
  
  #select data from tidy
  select(.id, term, estimate) |> 
  
  #pivot wider in order to define beta1 * beta2 (creating separate column)
  pivot_wider(
    names_from = term,
    values_from = estimate
  ) |> 
  
  #calculate log(b1 * b2) 
  mutate(log_est = log(abs(tmin * prcp)))

#Parameters to estimate confidence intervals
zval = qnorm(.975)

  #Take mean of all r^2 values
log_mean = mean(log_b1_b2_df$log_est)
  #estimate sd of all r^2 values
log_sd = sd(log_b1_b2_df$log_est)
  #record sample size
count = nrow(log_b1_b2_df)
  #calculate marginal error (used to calculate 95% CI)
me_log = zval * (log_sd/sqrt(count))
```

- log(b1\*b2) Mean: -5.8476894
- log(b1\*b2) 95% CI: (-5.8778749, -5.817504)

**Plot log(b1 \* b2)**

``` r
log_b1_b2_df |> 
  ggplot(aes(x = log_est)) +
  geom_density()
```

![](p8105_hw6_kl3453_files/figure-gfm/unnamed-chunk-16-1.png)<!-- -->

NOTE: Maybe due to personal misunderstanding but the product of beta1
and beta2 results in negative values for certain values and thus
produces a non-real value when performing the log of the product. Thus
the density plot is skewed.

# Problem 3

In this problem, you will analyze data gathered to understand the
effects of several variables on a child’s birthweight. This dataset,
available here, consists of roughly 4000 children and includes the
following variables:

Load and clean the data for regression analysis (i.e. convert numeric to
factor where appropriate, check for missing data, etc.).

**Load**

``` r
raw_birthweight_data =
  read_csv("./data/birthweight.csv") |> 
  janitor::clean_names()
```

    ## Rows: 4342 Columns: 20
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (20): babysex, bhead, blength, bwt, delwt, fincome, frace, gaweeks, malf...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

**Clean**

``` r
birthweight_df = 
  raw_birthweight_data |> 
  
  #convert frace to categorical var, convert to factor
  mutate(frace = factor(frace)) |> 
  
  #convert mrace to categorical var, convert to factor
  mutate(mrace = factor(mrace))
```

## Propose + Compare your Models

**Proposed Model**

The proposed model will be a linear regression as the outcome is a
continuous variable.

- BirthWeight = length, gestational age, sex, mrace, frace

  - Hypothesis: race of mother/father may act as social factors that may
    significantly affect birthweight.

``` r
proposed_model = lm(bwt ~ blength + gaweeks + babysex + mrace + frace, data = birthweight_df)
```

**Main Effect Model**

- BirthWeight = Length at Birth + Gestational Age

``` r
main_model = lm(bwt ~ blength + gaweeks, data = birthweight_df) 
```

**Three Way Model**

- BirthWeight = Head Circumference, Length, Baby Sex, and All
  Interactions

``` r
interaction_model = lm(bwt ~ blength + bhead + babysex + blength:bhead + blength:babysex + bhead:babysex + bhead:blength:babysex, data = birthweight_df)
```

### Comparing Models: Residuals vs. Predicted

**Create Test/Training Data**

``` r
cv_bwt_df = 
  crossv_mc(birthweight_df, 100) |> 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)) |> 
  mutate(
      prop_mod = map(train, \(df) lm(bwt ~ blength + gaweeks + babysex + mrace + frace, data = df)),
      main_mod = map(train, \(df) lm(bwt ~ blength + gaweeks, data = df)),
      inter_mod = map(train, \(df) lm(bwt ~ blength + bhead + babysex + blength:bhead + blength:babysex + bhead:babysex + bhead:blength:babysex, data = df))
      ) |> 
  mutate(
    rmse_prop = map2_dbl(prop_mod, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_main    = map2_dbl(main_mod, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_inter = map2_dbl(inter_mod, test, \(mod, df) rmse(model = mod, data = df)))
```

**Proposed Model: Residuals vs. Predictors**

``` r
#Take one test sample + plot the predictoed vs. residuals for each sample.
cv_bwt_df |> 
  pull(test) |> 
  nth(1) |> 
  as_tibble() |> 
  add_predictions(proposed_model) |> 
  add_residuals(proposed_model) |> 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() 
```

![](p8105_hw6_kl3453_files/figure-gfm/unnamed-chunk-23-1.png)<!-- -->

**Main Model: Residuals vs. Predictors**

``` r
cv_bwt_df |> 
  pull(test) |> 
  nth(1) |> 
  as_tibble() |> 
  add_predictions(main_model) |> 
  add_residuals(main_model) |> 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() 
```

![](p8105_hw6_kl3453_files/figure-gfm/unnamed-chunk-24-1.png)<!-- -->

**3 Way Model: Residuals vs. Predictors**

``` r
cv_bwt_df |> 
  pull(test) |> 
  nth(1) |> 
  as_tibble() |> 
  add_predictions(interaction_model) |> 
  add_residuals(interaction_model) |> 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() 
```

![](p8105_hw6_kl3453_files/figure-gfm/unnamed-chunk-25-1.png)<!-- -->

By comparing the models based on residuals and predictors, it seems they
all fit quite similarly.

- In more detail, it seems that the 3 way model fits this particular
  test sample a bit better as the scatterplot is more tightly comppacted
  around the resid = 0 line.

### Comparing Models: MSE

``` r
cv_bwt_df |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") |> 
  mutate(model = fct_inorder(model)) |> 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

![](p8105_hw6_kl3453_files/figure-gfm/unnamed-chunk-26-1.png)<!-- -->

As we can see, it seems the 3 way model performs slightly better than
the main and the proposed model in terms of model fit to the data.
